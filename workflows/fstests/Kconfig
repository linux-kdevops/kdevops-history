if KDEVOPS_WORKFLOW_ENABLE_FSTESTS

config HAVE_DISTRO_PREFERS_FSTESTS_WATCHDOG
	bool
	default n

config HAVE_DISTRO_PREFERS_FSTESTS_WATCHDOG_KILL
	bool
	default n

config HAVE_DISTRO_PREFERS_FSTESTS_WATCHDOG_RESET
	bool
	default n

choice
	prompt "Target filesystem to test"
	default FSTESTS_BTRFS

config FSTESTS_XFS
	bool "xfs"
	help
	  This will target testing the xfs filesystem.

config FSTESTS_BTRFS
	bool "btrfs"
	help
	  This will target testing the btrfs filesystem.

config FSTESTS_EXT4
	bool "ext4"
	help
	  This will target testing the ext4 filesystem.

endchoice

config FSTESTS_FSTYP
	string "The filesystem to test with fstests"
	default "xfs" if FSTESTS_XFS
	default "btrfs" if FSTESTS_BTRFS
	default "ext4" if FSTESTS_EXT4
	help
	  The filesystem to test. This will be automatically set depending on
	  the above choice, you however can override this manually.

config FSTESTS_WATCHDOG
	bool "Enable kdevops fstests watchdog"
	default y if HAVE_DISTRO_PREFERS_FSTESTS_WATCHDOG
	default n if !HAVE_DISTRO_PREFERS_FSTESTS_WATCHDOG
	depends on KERNEL_CI
	help
	  Enable the fstests watchdog which lets you keep tabs on progress
	  of fstests on different spawned systems.

	  Enabling this option will allow the kdevops fstests_watchdog.py to
	  run and log into the workflows/fstests/watchdog/$FSTYP.txt the status
	  of all known tests.

	  It is safe to enable as no action is taken by default, it is just
	  informational. If you however don't even want this information logged
	  you can disable this.

if FSTESTS_WATCHDOG

config FSTESTS_WATCHDOG_CHECK_TIME
	int "How often to run the festests_watchdog in seconds"
	default 5
	help
	  How often to trigger running the fstests watchdog, in seconds.

config FSTESTS_WATCHDOG_MAX_NEW_TEST_TIME
	int "Max minutes to wait for a new test before assuming a hang"
	default 60
	help
	  Max value of time in minutes a new test should take before assuming
	  the test is hung.

	  Once a test has completed or failed fstests captures the amount of
	  seconds it took to run that test on a file called check.time. This
	  file consists of two columns, the first with the test name and the
	  second column with the amount of time in seconds it took to run a
	  test. When we run a test for the first time there is no known prior
	  last test time, as there would be no check.time files present from a
	  prior run.

	  The amount of time it takes to run a test will also depend highly on
	  the system, drive and filesystem you are running the test on and so
	  check.time values are completely system specific. However, we can
	  often run into a test which is hung but fstests seems to keep running,
	  without providing feedback about a possibly hung test. In order to
	  tell if a test is hung we must define a value for max time any new test
	  can take. This value is system specific and so must be defined by the
	  person configuring the test, however sensible default values are
	  defined.

	  The kdevops fstests_watchdog.py uses this max value to know when a
	  test is on a system is hung for a test's first run. If a test had
	  already completed before, and so had an entry for the test on the
	  last test's check.time file for the target system, other heuristics
	  are used.

	  Setting this value is only informational, so that fstests_watchdog.py
	  can print a status of "hung" suspect when it finds a test goes over
	  this value on a first run.

config FSTESTS_WATCHDOG_HUNG_MULTIPLIER_LONG_TESTS
	int "Multiplier for amount of time before assuming a test is hung"
	default 10
	help
	  If we know a test took 1 minute the last time we ran it, setting the
	  multiplier to 10 will let the watchdog decide a test is hung if 10
	  minutes have passed and the test has not completed yet.

	  This multiplier is only used for tests for which we have a prior
	  last run time and that run time is greater than 30 seconds.

config FSTESTS_WATCHDOG_HUNG_FAST_TEST_MAX_TIME
	int "Max time in minutes to wait before declaring quick tests as hung"
	default 5
	help
	  If we know a test took between 1 second and 30 seconds to run in a
	  prior test we can safely assign a timeout value in minutes for these
	  quick tests for which we will let run before allowing the fstests
	  watchdog to assume the test is hung.

config FSTESTS_WATCHDOG_KILL_TASKS_ON_HANG
	bool "Enable killing local tasks on hang detection"
	default y if HAVE_DISTRO_PREFERS_FSTESTS_WATCHDOG_KILL
	default n if !HAVE_DISTRO_PREFERS_FSTESTS_WATCHDOG_KILL
	help
	  Enable the fstest watchdog to kill local controller tasks and if
	  enabled send a report if a hang / timeout occurs but leave the
	  systems which are hung / timed out alive for further inspection.

config FSTESTS_WATCHDOG_RESET_HUNG_SYSTEMS
	bool "Reset systems when the watchdog detects they are hung"
	default y if HAVE_DISTRO_PREFERS_FSTESTS_WATCHDOG_RESET
	default n if !HAVE_DISTRO_PREFERS_FSTESTS_WATCHDOG_RESET
	depends on VAGRANT
	depends on FSTESTS_WATCHDOG_KILL_TASKS_ON_HANG
	help
	  If this option is enabled, kdevops will reset all systems after a
	  hang is detected. This is a bad idea unless you know what you are
	  doing, ie, if this is option is enabled for you automatically.

	  The tests which caused the hangs found will be logged. Enabling
	  this is only desirable if you don't care to manually inspect
	  hosed systems when a hang happens. This may be useful in the
	  future if we enable automatic tasks which create a baseline for
	  you, for instance, but for this to be more useful, we'd likely
	  have to also implement a way to try to capture kernel logs
	  before a reset.

	  We currently only enable this for vagrant provisioning, given we have
	  to figure out a unified way to express a reset for cloud solution and
	  also figure out a way to enable this for bare metal. For vagrant we
	  currently use 'virsh reset' and so this works only if on libvirt.

endif # FSTESTS_WATCHDOG

if FSTESTS_XFS

menu "Configure how to test XFS"
source "workflows/fstests/xfs/Kconfig"
endmenu

endif # FSTESTS_XFS

if FSTESTS_BTRFS

menu "Configure how to test btrfs"
source "workflows/fstests/btrfs/Kconfig"
endmenu

endif # FSTESTS_BTRFS

if FSTESTS_EXT4

menu "Configure how to test ext4"
source "workflows/fstests/ext4/Kconfig"
endmenu

endif # FSTESTS_EXT4

config FSTESTS_GIT
	string "The fstests git tree to clone"
	default "https://git.kernel.org/pub/scm/fs/xfs/xfstests-dev.git" if !GIT_ALTERNATIVES
	default "https://github.com/linux-kdevops/fstests.git" if GIT_LINUX_KDEVOPS_GITHUB
	default "https://gitlab.com/linux-kdevops/fstests.git" if GIT_LINUX_KDEVOPS_GITLAB
	default "https://github.com/btrfs/fstests.git" if FSTESTS_BTRFS
	help
	  The fstests git tree to clone.

config FSTESTS_DATA
	string "Where to clone the fstests git tree to"
	default "{{data_path}}/fstests"
	help
	  This is the target location of where to clone the above git tree.
	  Note that {{data_path}} corresponds to the location set by the
	  configuration option CONFIG_WORKFLOW_DATA_PATH.

config FSTESTS_DATA_TARGET
	string "The target fstests install directory"
	default "/var/lib/xfstests"
	help
	  The directory where fstests will be installed. Modifying this probably
	  won't work well yet.

choice
	prompt "Strategy for device pool"
	default FSTESTS_TESTDEV_SPARSEFILE_GENERATION

config FSTESTS_TESTDEV_SPARSEFILE_GENERATION
	bool "Create sparse files for test devices"
	help
	  When testing a filesystem with fstests you must provide the
	  test devices to be used to test. By selecting this option
	  sparse files will be created for you on a target path, and
	  loopback devices will be set up for you so you can use these
	  loopback devices to test the filesystem.

	  This is useful if you don't really want to test creating a filesystem
	  against real block devices or are constrained / limited by the amount
	  of block devices you have. By using sparse files you are also
	  reducing the amount of hard drive space you actually need to only the
	  amount of actual space used by all the tests. This varies by the
	  filesystem you are testing.

	  We'll create 15 sparse files for you, and so you can run tests which
	  require up to 15 block devices. The TEST_DEV is set to /dev/loop16.
	  If a LOGWRITES_DEV is used this /dev/loop15 is used.
	  If a SCRATCH_RTDEV is used this /dev/loop14 is used.

	  The SCRATCH_DEV_POOL is set to these devices:

	   /dev/loop5   /dev/loop6   /dev/loop7   /dev/loop8
	   /dev/loop9   /dev/loop10  /dev/loop11  /dev/loop12

	  With this strategy these loopback devices currently remain unused:

	   /dev/loop13

endchoice

if FSTESTS_TESTDEV_SPARSEFILE_GENERATION

config FSTESTS_SPARSE_DEV
	string "Device to use to create a filesystem on for sparse files"
	default "/dev/nvme1n1" if VAGRANT
	default "/dev/nvme2n1" if TERRAFORM_AWS_INSTANCE_M5AD_4XLARGE
	default "/dev/nvme1n1" if TERRAFORM_GCE
	default "/dev/sde" if TERRAFORM_AZURE
	default TERRAFORM_OCI_SPARSE_VOLUME_DEVICE_FILE_NAME if TERRAFORM_OCI
	help
	  The device to use to create a filesystem on where we will place
	  sparse files.

choice
	prompt "Filesystem to use where sparse files will live"
	default FSTESTS_SPARSE_BTRFS

config FSTESTS_SPARSE_XFS
	bool "xfs"
	help
	  This will target testing the xfs filesystem.

config FSTESTS_SPARSE_BTRFS
	bool "btrfs"
	help
	  This will target testing the btrfs filesystem.

config FSTESTS_SPARSE_EXT4
	bool "ext4"
	help
	  This will target testing the ext4 filesystem.

endchoice

config FSTESTS_SPARSE_FSTYPE
	string "Filesystem to use to create where the sparse files will live"
	default "xfs" if FSTESTS_SPARSE_XFS
	default "btrfs" if FSTESTS_SPARSE_BTRFS
	default "ext4" if FSTESTS_SPARSE_EXT4
	help
	  The filesystem to use where we will place the generated sparse files.
	  This is not the filesystem we will test, this is just where the sparse
	  files used will live.

config FSTESTS_SPARSE_LABEL
	string "Filesystem label to use for the filesystem where sparsefiles live"
	default "sparsefiles"
	help
	  The filesystem label to create and later use to mount the partition on
	  the /etc/fstab file to which represents where sparsefiles live.

config FSTESTS_SPARSE_FILE_PATH
	string "Path to directory where to generate sparse files"
	default "/media/sparsefiles"
	help
	  The directory where to create sparse files to be used to represent
	  actual devices used.

config FSTESTS_SPARSE_FILE_SIZE
	string "Size of the sparse files to use per target device"
	default "20G"
	help
	  The size of the sparse files to create, this is the -s argument passed
	  to the command truncate.

config FSTESTS_SPARSE_FILENAME_PREFIX
	string "The sparse file name prefix to use"
	default "sparse-disk"
	help
	  This is the prefix for the name of the sparse file to create.
	  For instance if FSTESTS_SPARSE_FILE_PATH is set to /media/truncated
	  and you set this prefix to sparse-disk, the first sparse file to create
	  will be named /media/truncated/sparse-disk5. The name used is simply for
	  pure convenience to the developer and to make it clear what type of
	  file backing is provided for the loopback device.

endif # FSTESTS_TESTDEV_SPARSEFILE_GENERATION

config FSTESTS_TEST_DEV
	string "The device to use TEST_DEV on fstests"
	default "/dev/loop16" if FSTESTS_TESTDEV_SPARSEFILE_GENERATION
	help
	  To test with fstests one must set the TEST_DEV variable, this sets
	  the TEST_DEV to use.

config FSTESTS_TEST_DEV_ZNS
	string "The device to use TEST_DEV on fstests for ZNS testing"
	depends on VAGRANT_ENABLE_ZNS
	default "/dev/nvme4n1" if QEMU_ENABLE_NVME_ZNS
	help
	  To test with fstests one must set the TEST_DEV variable, this sets
	  the TEST_DEV to use when testing with ZNS drives.

config FSTESTS_TEST_DIR
	string "The path to use for the fstests TEST_DIR variable"
	default "/media/test"
	help
	  To test with fstests one must set the TEST_DEV variable, this sets
	  the TEST_DEV to use.

	# default $(shell, for i in $(seq 5 11) echo /dev/loop$i) if FSTESTS_TESTDEV_SPARSEFILE_GENERATION
config FSTESTS_SCRATCH_DEV_POOL
	string "The list of devices to set in SCRATCH_DEV_POOL"
	default "/dev/loop5 /dev/loop6 /dev/loop7 /dev/loop8 /dev/loop9 /dev/loop10 /dev/loop11 /dev/loop12" if FSTESTS_TESTDEV_SPARSEFILE_GENERATION
	help
	  To set of spare devices to use for the fstests SCRATCH_DEV_POOL.

config FSTESTS_SCRATCH_DEV_POOL_ZNS
	string "The list of devices to set in SCRATCH_DEV_POOL for ZNS testing"
	depends on VAGRANT_ENABLE_ZNS
	default "/dev/nvme5n1 /dev/nvme6n1 /dev/nvme7n1 /dev/nvme8n1 /dev/nvme9n1 /dev/nvme10n1 /dev/nvme11n1 /dev/nvme12n1" if QEMU_ENABLE_NVME_ZNS
	help
	  To set of spare devices to use for the fstests SCRATCH_DEV_POOL for ZNS testing.

config FSTESTS_SCRATCH_MNT
	string "The path to use for the fstests SCRATCH_MNT variable"
	default "/media/scratch"
	help
	  This sets the SCRATCH_MNT variable.

config FSTESTS_LOGWRITES_DEV
	string "The fstests LOGWRITES_DEV to use"
	default "/dev/loop15" if FSTESTS_TESTDEV_SPARSEFILE_GENERATION
	help
	  To set of spare devices to use for the fstests SCRATCH_DEV_POOL.

config FSTESTS_SCRATCH_LOGDEV
	string "The fstests SCRATCH_LOGDEV to use"
	default "/dev/loop15" if FSTESTS_TESTDEV_SPARSEFILE_GENERATION
	help
	  To set devices to use for the SCRATCH_LOGDEV.

config FSTESTS_LOGWRITES_DEV
	string "The fstests LOGWRITES_DEV to use"
	default "/dev/loop15" if FSTESTS_TESTDEV_SPARSEFILE_GENERATION
	help
	  To set devices to use for the LOGWRITES_DEV.

if FSTESTS_XFS

config FSTESTS_SCRATCH_RTDEV
	string "The fstests SCRATCH_RTDEV to use"
	default "/dev/loop14" if FSTESTS_TESTDEV_SPARSEFILE_GENERATION
	help
	  To set devices to use for the SCRATCH_RTDEV.

endif # FSTESTS_XFS

config FSTESTS_SETUP_SYSTEM
	bool "Help setup system if something is found missing or broken"
	default y
	help
	  This adds adds users / groups if missing. Additionally if
	  a service is not avaiable it ensures to start it. These quirks should
	  all be moved as part of the ansible role for fstests eventually.

config FSTESTS_RUN_TESTS
	bool "Run fstests"
	default y
	help
	  Disable this to only install dependencies for fstests, and so the
	  full set of fstests won't be run.

config FSTESTS_RUN_AUTO_GROUP_TESTS
	bool "Run fstests of group 'auto'"
	depends on FSTESTS_RUN_TESTS
	default y
	help
	  The 'auto' test group is a good choice for running regression tests.
	  Disable this to run also the tests that are not in the 'auto' group.

config FSTESTS_RUN_CUSTOM_GROUP_TESTS
	string "Run a custom group of fstests"
	default "auto" if FSTESTS_RUN_AUTO_GROUP_TESTS
	depends on FSTESTS_RUN_TESTS
	help
	  To configure fstests to run specific group of tests instead of the
	  'auto' group.

config FSTESTS_RUN_CUSTOM_TESTS
	string "Run a custom set of fstests"
	depends on FSTESTS_RUN_TESTS
	help
	  To configure fstests to run specific set of tests/groups.
	  When FSTESTS_RUN_AUTO_GROUP_TESTS is enabled, the custom test are run
	  in addition to the auto group tests. To run only the custom tests,
	  disable FSTESTS_RUN_AUTO_GROUP_TESTS. The custom tests do not override
	  expunge lists. If a custom test is listed in expunge list, it will not
	  run. Similarly, if a custom test is listed as a large disk test, it
	  will not run if FSTESTS_RUN_LARGE_DISK_TESTS is disabled.

config FSTESTS_RUN_LARGE_DISK_TESTS
	bool "Run fstests that require large disk"
	depends on FSTESTS_RUN_TESTS
	default y
	help
	  Disable this to avoid running tests that require a "large disk"
	  to run. The "large disk" requirement is test dependent, but
	  typically, it means a disk with capacity of at several 10G.

endif # KDEVOPS_WORKFLOW_ENABLE_FSTESTS
